{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b206e6d",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Mixture of Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3f715",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use multiple models (ARIMA, ETS, Random Forest) to forecast time series data for multiple SKUs and then combine them using a Mixture of Experts model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the data\n",
    "inventory_data = pd.read_csv('Domestic Auto Inventories.csv', index_col='DATE', parse_dates=True)\n",
    "production_data = pd.read_csv('Domestic Auto Production.csv', index_col='DATE', parse_dates=True)\n",
    "sales_data = pd.read_csv('Total Vehicle Sales.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "df = pd.concat([inventory_data, production_data, sales_data], axis=1)\n",
    "\n",
    "# Fill missing values with forward fill first, then backward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Define functions to train models and calculate metrics\n",
    "def train_models_for_sku(sku_data):\n",
    "    train, test = sku_data[sku_data.index < '2024-01-01'], sku_data[sku_data.index >= '2024-01-01']\n",
    "    arima_model = ARIMA(train, order=(5, 1, 0)).fit()\n",
    "    ets_model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()\n",
    "    X = np.arange(len(train)).reshape(-1, 1)\n",
    "    y = train.values\n",
    "    rf_model = RandomForestRegressor(n_estimators=100).fit(X, y)\n",
    "    arima_forecast = arima_model.forecast(steps=len(test))\n",
    "    ets_forecast = ets_model.forecast(steps=len(test))\n",
    "    rf_forecast = rf_model.predict(np.arange(len(train), len(train) + len(test)).reshape(-1, 1))\n",
    "    metrics = {\n",
    "        'ARIMA': calculate_metrics(test, arima_forecast),\n",
    "        'ETS': calculate_metrics(test, ets_forecast),\n",
    "        'Random Forest': calculate_metrics(test, rf_forecast)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    mape = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "    wape = np.sum(np.abs(true_values - predicted_values)) / np.sum(np.abs(true_values))\n",
    "    return mae, mape, wape\n",
    "\n",
    "def train_mixture_of_experts(sku_data):\n",
    "    train, test = sku_data[sku_data.index < '2024-01-01'], sku_data[sku_data.index >= '2024-01-01']\n",
    "    arima_model = ARIMA(train, order=(5, 1, 0)).fit()\n",
    "    ets_model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()\n",
    "    X = np.arange(len(train)).reshape(-1, 1)\n",
    "    y = train.values\n",
    "    rf_model = RandomForestRegressor(n_estimators=100).fit(X, y)\n",
    "    arima_forecast = arima_model.forecast(steps=len(test))\n",
    "    ets_forecast = ets_model.forecast(steps=len(test))\n",
    "    rf_forecast = rf_model.predict(np.arange(len(train), len(train) + len(test)).reshape(-1, 1))\n",
    "    combined_forecasts = np.vstack((arima_forecast, ets_forecast, rf_forecast)).T\n",
    "    meta_model = LinearRegression()\n",
    "    meta_model.fit(combined_forecasts, test)\n",
    "    meta_forecast = meta_model.predict(combined_forecasts)\n",
    "    metrics = calculate_metrics(test, meta_forecast)\n",
    "    return metrics\n",
    "\n",
    "# Train models and evaluate them\n",
    "results = pd.DataFrame(columns=['SKU', 'Model', 'MAE', 'MAPE', 'WAPE'])\n",
    "moe_results = pd.DataFrame(columns=['SKU', 'Model', 'MAE', 'MAPE', 'WAPE'])\n",
    "\n",
    "for sku in df.columns:\n",
    "    sku_data = df[sku]\n",
    "    metrics = train_models_for_sku(sku_data)\n",
    "    for model_name, (mae, mape, wape) in metrics.items():\n",
    "        results = results.append({\n",
    "            'SKU': sku,\n",
    "            'Model': model_name,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'WAPE': wape\n",
    "        }, ignore_index=True)\n",
    "    mae, mape, wape = train_mixture_of_experts(sku_data)\n",
    "    moe_results = moe_results.append({\n",
    "        'SKU': sku,\n",
    "        'Model': 'Mixture of Experts',\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'WAPE': wape\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Combine results\n",
    "all_results = pd.concat([results, moe_results], ignore_index=True)\n",
    "all_results = all_results.sort_values(by=['SKU', 'MAE', 'MAPE', 'WAPE'], ascending=True)\n",
    "all_results\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
