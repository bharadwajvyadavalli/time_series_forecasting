{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6712fc59",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84f58f",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use multiple models (ARIMA, ETS, Random Forest, XGBoost, SARIMA, and Mixture of Experts) to forecast time series data for multiple SKUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries for processing and modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Load the data from uploaded files\n",
    "inventory_data = pd.read_csv('Domestic Auto Inventories.csv', index_col='DATE', parse_dates=True)\n",
    "production_data = pd.read_csv('Domestic Auto Production.csv', index_col='DATE', parse_dates=True)\n",
    "sales_data = pd.read_csv('Total Vehicle Sales.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "df = pd.concat([inventory_data, production_data, sales_data], axis=1)\n",
    "\n",
    "# Fill missing values with forward fill first, then backward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Function to calculate performance metrics\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    mape = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "    wape = np.sum(np.abs(true_values - predicted_values)) / np.sum(np.abs(true_values))\n",
    "    return mae, mape, wape\n",
    "\n",
    "# Training functions for various models\n",
    "def train_arima(train, test):\n",
    "    model = ARIMA(train, order=(5, 1, 0)).fit()\n",
    "    forecast = model.forecast(steps=len(test))\n",
    "    return forecast\n",
    "\n",
    "def train_ets(train, test):\n",
    "    model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()\n",
    "    forecast = model.forecast(steps=len(test))\n",
    "    return forecast\n",
    "\n",
    "def train_rf(train, test):\n",
    "    X = np.arange(len(train)).reshape(-1, 1)\n",
    "    y = train.values\n",
    "    model = RandomForestRegressor(n_estimators=100).fit(X, y)\n",
    "    forecast = model.predict(np.arange(len(train), len(train) + len(test)).reshape(-1, 1))\n",
    "    return forecast\n",
    "\n",
    "def train_xgb(train, test):\n",
    "    X = np.arange(len(train)).reshape(-1, 1)\n",
    "    y = train.values\n",
    "    model = XGBRegressor(n_estimators=100).fit(X, y)\n",
    "    forecast = model.predict(np.arange(len(train), len(train) + len(test)).reshape(-1, 1))\n",
    "    return forecast\n",
    "\n",
    "def train_sarima(train, test):\n",
    "    model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 0, 12)).fit()\n",
    "    forecast = model.forecast(steps=len(test))\n",
    "    return forecast\n",
    "\n",
    "def train_mixture_of_experts(combined_forecasts, test):\n",
    "    meta_model = LinearRegression()\n",
    "    meta_model.fit(combined_forecasts, test)\n",
    "    meta_forecast = meta_model.predict(combined_forecasts)\n",
    "    return meta_forecast\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results = pd.DataFrame(columns=['SKU', 'Model', 'MAE', 'MAPE', 'WAPE'])\n",
    "moe_results = pd.DataFrame(columns=['SKU', 'Model', 'MAE', 'MAPE', 'WAPE'])\n",
    "\n",
    "# Loop through each SKU column in the DataFrame\n",
    "for sku in df.columns:\n",
    "    print(f\"Processing SKU: {sku}\")\n",
    "    sku_data = df[sku].dropna()\n",
    "    train, test = sku_data[sku_data.index < '2024-01-01'], sku_data[sku_data.index >= '2024-01-01']\n",
    "\n",
    "    # Train each model and get forecasts\n",
    "    forecasts = {\n",
    "        'ARIMA': train_arima(train, test),\n",
    "        'ETS': train_ets(train, test),\n",
    "        'Random Forest': train_rf(train, test),\n",
    "        'XGBoost': train_xgb(train, test),\n",
    "        'SARIMA': train_sarima(train, test)\n",
    "    }\n",
    "    \n",
    "    for model_name, forecast in forecasts.items():\n",
    "        mae, mape, wape = calculate_metrics(test, forecast)\n",
    "        results = results.append({\n",
    "            'SKU': sku,\n",
    "            'Model': model_name,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'WAPE': wape\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    # Prepare combined forecasts for Mixture of Experts\n",
    "    combined_forecasts = np.vstack(list(forecasts.values())).T\n",
    "    meta_forecast = train_mixture_of_experts(combined_forecasts, test)\n",
    "    mae, mape, wape = calculate_metrics(test, meta_forecast)\n",
    "    moe_results = moe_results.append({\n",
    "        'SKU': sku,\n",
    "        'Model': 'Mixture of Experts',\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'WAPE': wape\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Combine results\n",
    "all_results = pd.concat([results, moe_results], ignore_index=True)\n",
    "all_results = all_results.sort_values(by=['SKU', 'MAE', 'MAPE', 'WAPE'], ascending=True)\n",
    "print(all_results)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
