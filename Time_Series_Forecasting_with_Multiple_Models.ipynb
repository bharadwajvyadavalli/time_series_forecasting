{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras.optimizers import Adam\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "inventory_data = pd.read_csv('Domestic Auto Inventories.csv', index_col='DATE', parse_dates=True)\n",
    "production_data = pd.read_csv('Domestic Auto Production.csv', index_col='DATE', parse_dates=True)\n",
    "sales_data = pd.read_csv('Total Vehicle Sales.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "df = pd.concat([inventory_data, production_data, sales_data], axis=1)\n",
    "\n",
    "# Fill missing values with forward fill first, then backward fill\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)"
   ],
   "id": "b0dd20bf2b402350"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define functions to train models and calculate metrics\n",
    "def train_models_for_sku(sku_data):\n",
    "    train, test = sku_data[sku_data.index < '2024-01-01'], sku_data[sku_data.index >= '2024-01-01']\n",
    "    \n",
    "    # Train each expert model on the training data\n",
    "    arima_model = ARIMA(train, order=(5, 1, 0)).fit()\n",
    "    ets_model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()\n",
    "    X = np.arange(len(train)).reshape(-1, 1)\n",
    "    y = train.values\n",
    "    rf_model = RandomForestRegressor(n_estimators=100).fit(X, y)\n",
    "    \n",
    "    # Generate predictions on training data\n",
    "    arima_forecast_train = arima_model.predict(start=train.index[0], end=train.index[-1])\n",
    "    ets_forecast_train = ets_model.predict(start=train.index[0], end=train.index[-1])\n",
    "    rf_forecast_train = rf_model.predict(X)\n",
    "    \n",
    "    # Generate predictions on test data\n",
    "    arima_forecast_test = arima_model.forecast(steps=len(test))\n",
    "    ets_forecast_test = ets_model.forecast(steps=len(test))\n",
    "    rf_forecast_test = rf_model.predict(np.arange(len(train), len(train) + len(test)).reshape(-1, 1))\n",
    "    \n",
    "    return arima_forecast_train, ets_forecast_train, rf_forecast_train, arima_forecast_test, ets_forecast_test, rf_forecast_test, train, test\n",
    "\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    mape = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "    wape = np.sum(np.abs(true_values - predicted_values)) / np.sum(np.abs(true_values))\n",
    "    return mae, mape, wape\n",
    "\n",
    "# Example: Prepare data for a single SKU (column)\n",
    "sku_data = df.iloc[:, 0]  # Assuming SKU is the first column\n",
    "\n",
    "# Train models and get forecasts\n",
    "arima_forecast_train, ets_forecast_train, rf_forecast_train, arima_forecast_test, ets_forecast_test, rf_forecast_test, train, test = train_models_for_sku(sku_data)"
   ],
   "id": "23992a24b87265d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Simplified gating network definition\n",
    "def build_gating_network(input_dim, num_experts):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    output_layer = Dense(num_experts, activation='softmax')(input_layer)\n",
    "    gating_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return gating_model\n",
    "\n",
    "# Combine forecasts on training data\n",
    "combined_forecasts_train = np.vstack((arima_forecast_train, ets_forecast_train, rf_forecast_train)).T\n",
    "\n",
    "# Train the gating network using expert predictions on training data\n",
    "gating_network = build_gating_network(combined_forecasts_train.shape[1], num_experts=3)\n",
    "gating_network.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "gating_network.fit(combined_forecasts_train, train, epochs=50, batch_size=32, verbose=1)"
   ],
   "id": "6133224606b8628e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine forecasts on test data\n",
    "combined_forecasts_test = np.vstack((arima_forecast_test, ets_forecast_test, rf_forecast_test)).T\n",
    "\n",
    "# Make predictions on the test data using the trained gating network\n",
    "gating_weights_test = gating_network.predict(combined_forecasts_test)\n",
    "\n",
    "# Calculate the final MoE predictions as a weighted sum of expert predictions on test data\n",
    "moe_predictions_test = np.sum(gating_weights_test * combined_forecasts_test, axis=1)\n",
    "\n",
    "# Evaluate the MoE model on the test set\n",
    "mse_test = np.mean((moe_predictions_test - test) ** 2)\n",
    "print(f'MoE Model MSE on test data: {mse_test:.4f}')"
   ],
   "id": "51c8beb9ebc68be9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
